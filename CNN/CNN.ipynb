{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from mlxtend.data import loadlocal_mnist\n",
    "from pathlib import Path"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def min_max_normalizer(images):\n",
    "    '''\n",
    "        Min-Max normalizer for images\n",
    "    '''\n",
    "    images[:,0,:,:] = (images[:,0,:,:]-np.min(images[:,0,:,:]))/(images[:,0,:,:].max()-images[:,0,:,:].min())\n",
    "    images[:,1,:,:] = (images[:,1,:,:]-np.min(images[:,1,:,:]))/(images[:,1,:,:].max()-images[:,1,:,:].min())\n",
    "    images[:,2,:,:] = (images[:,2,:,:]-np.min(images[:,2,:,:]))/(images[:,2,:,:].max()-images[:,2,:,:].min())\n",
    "    return images"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class Convolution_Layer():\n",
    "    def __init__(self, input, filter_size, bias=True, stride=1, padding=0, dilation=1):\n",
    "        '''\n",
    "            Initializing a Conv layer with padding, strides and dilation options\n",
    "        '''\n",
    "        self.padding = padding\n",
    "        self.stride = stride\n",
    "        self.dilation = dilation\n",
    "\n",
    "        input = input.reshape(len(input), 3, 32, 32)\n",
    "\n",
    "        self.N, self.C, self.H, self.W = input.shape\n",
    "        self.F, self.C, self.HH, self.WW = filter_size\n",
    "\n",
    "        self.H_ = int((self.H + 2*padding - (dilation)*(self.HH-1)-1)/stride) + 1\n",
    "        self.W_ = int((self.W + 2*padding - (dilation)*(self.WW-1)-1)/stride) + 1        \n",
    "        \n",
    "        self.weights = np.random.normal(loc=0,scale=1, size=filter_size)\n",
    "        self.output = np.zeros((self.N, self.F, self.H_, self.W_))\n",
    "\n",
    "\n",
    "    def forward(self,input):\n",
    "        pad = self.padding\n",
    "        input = input.reshape(len(input), 3, 32, 32)\n",
    "        self.input = np.pad(input, ((0,0),(0,0),(pad,pad),(pad,pad)))\n",
    "\n",
    "        # Loop over every location in inp_height * inp_width for the whole batch\n",
    "        j_HH = (self.dilation)*(self.HH-1)+1\n",
    "        j_WW = (self.dilation)*(self.WW-1)+1\n",
    "        \n",
    "        d_weigths = np.zeros((self.F, self.C, j_HH, j_WW))\n",
    "        for f in range(self.F):\n",
    "            for c in range(self.C):\n",
    "                for hh in range(j_HH):\n",
    "                    if(hh%self.dilation)==0:\n",
    "                        for ww in range(j_WW):\n",
    "                            if(ww%self.dilation)==0:\n",
    "                                d_weigths[f,c,hh,ww] = self.weights[f,c,int(hh/self.dilation), int(ww/self.dilation)]\n",
    "        \n",
    "        self.weights = d_weigths\n",
    "      \n",
    "        for n in range(self.N):\n",
    "            for f in range(self.F):\n",
    "                for h in range(self.H_):\n",
    "                    for w in range(self.W_):\n",
    "                        self.output[n,f,h,w] = np.sum(self.input[n,\n",
    "                                                                 :,\n",
    "                                                                 h*self.stride:h*self.stride+j_HH,\n",
    "                                                                 w*self.stride:w*self.stride+j_WW] * d_weigths[f,:,:,:])\n",
    "        # Output will be of the size (Batch_size, out_channels, out_height, out_width)\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, grad_of_output_size):\n",
    "        # Naive Implementation\n",
    "        j_HH = (self.dilation)*(self.HH-1)+1\n",
    "        j_WW = (self.dilation)*(self.WW-1)+1\n",
    "        \n",
    "        grad = np.zeros_like(self.weights)\n",
    "        for n in range(self.N):\n",
    "            for f in range(self.F):\n",
    "                for hi in range(self.H_):\n",
    "                    for wi in range(self.W_):\n",
    "                        grad[f] += self.input[n, :, hi*self.stride:hi*self.stride+j_HH, wi*self.stride:wi*self.stride+j_WW] * grad_of_output_size[n, f, hi, wi]\n",
    "\n",
    "        return grad\n",
    "\n",
    "    def set_weights(self, new_weights):\n",
    "        self.weights = new_weights\n",
    "        \n",
    "    def update_weights(self, lr, grad):\n",
    "        self.weights = self.weights - lr*grad\n"
   ],
   "outputs": [],
   "metadata": {}
  },

  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data_batch = []\n",
    "label_batch = []\n",
    "for i in range(5):\n",
    "    file = f'cifar10/data_batch_{i+1}'\n",
    "    def unpickle(file):\n",
    "        import pickle\n",
    "        with open(file, 'rb') as fo:\n",
    "            dict = pickle.load(fo, encoding='bytes')\n",
    "        return dict\n",
    "    data_batch_ = unpickle(file)\n",
    "    data_batch.append(data_batch_[b'data'])\n",
    "    label_batch.append(data_batch_[b'labels'])\n",
    "\n",
    "# Test data    \n",
    "file = f'cifar10/test_batch'\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "test_data = unpickle(file)[b'data']\n",
    "test_labels = unpickle(file)[b'labels']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "filter_size = (3,3,3,3)\n",
    "\n",
    "def gaussian(i, sigma):\n",
    "\tG = (np.exp(-0.5*((i)/sigma)**2))/(math.pi*2*sigma**2)\n",
    "\treturn G\n",
    "\n",
    "new_weights = np.zeros(filter_size)\n",
    "for i in range(filter_size[0]):\n",
    "    for j in range(filter_size[1]):\n",
    "        for k in range(filter_size[2]):\n",
    "            for l in range(filter_size[3]):\n",
    "                new_weights[i,j,k,l] = gaussian((k-(filter_size[2]//2))**2 + (l-(filter_size[3]//2))**2, i*0.2+1)\n",
    "        \n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class L2_loss():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def forward(self, C0_output,C_output):\n",
    "        loss = np.sum(np.square(C0_output-C_output))\n",
    "        return loss\n",
    "    \n",
    "    def backward(self, C0_output,C_output):\n",
    "        grad = 2 * (C0_output - C_output)\n",
    "        return grad\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "l2_loss = L2_loss()\n",
    "\n",
    "filter_size = (20,3,5,5)\n",
    "new_weights = np.random.uniform(-1,1,size=filter_size)\n",
    "\n",
    "inputs = data_batch[0][:100]\n",
    "\n",
    "conv = Convolution_Layer(inputs,filter_size=filter_size, bias=True, stride=1, padding=0, dilation=1)\n",
    "conv.set_weights(new_weights)\n",
    "C_output = conv.forward(inputs)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "EPOCHS = 10\n",
    "lr = 3e-3\n",
    "\n",
    "losses = []\n",
    "\n",
    "for e in range(EPOCHS):\n",
    "    C_output = conv.forward(inputs)\n",
    "    C_output = min_max_normalizer(C_output)\n",
    "    loss = l2_loss.forward(C0_output, C_output)\n",
    "    losses.append(loss)\n",
    "    print(\"EPOCH : \",e, \"LOSS : \",loss)\n",
    "    loss_grad = l2_loss.backward(C0_output,C_output)\n",
    "    grad = conv.backward(loss_grad)\n",
    "    conv.update_weights(lr, grad)\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
